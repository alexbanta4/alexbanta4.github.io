### The Problem

We are interested in applying Neural Networks in music classification. More specifically, we would like to build a Neural Network architecture to identify whether a particular recording is a cover of another recording, e.g. it is a different performance of the same song by a different artist. We plan to adopt the architecture and experiments from a number of papers that do this. Our goal is to test the effectiveness of our architecture in being able to identify multiple versions of the same song, some of which may differ in key, tempo, instrumentation, and style.
  Music-hosting websites often want to know whether or not a song is a cover of an already published song, so that they can make sure it is appropriately labeled as such. In addition, this
is of interest in the music industry when it comes to plagiarism; often songs are covered or used without the permission of the initial artist. Since the neural network is being trained to identify cover songs based on similarity of content, this could possibly be expanded to identify plagiarism. A neural network that can take in an audio file and identify whether or not it is a cover song would be useful for processing the large volume of such songs. In terms of intellectual interest, it will be very interesting to work with a neural network aimed at classifying something as complex as a song, and to find out what a network needs in order to do so effectively.

### Network

![Figure 1]((https://alexbanta4.github.com/Loss Graph.png)

Our network architecture is a four-layer convolutional network followed by a linear layer, a sigmoid, and a second linear layer. Two songs are passed through the convolutional network, and then through a linear layer and a sigmoid layer. The absolute value of the difference of the sigmoid representation of both songs is then passed through a final linear layer, which outputs the modelâ€™s classification.
  We trained using an adaptive learning rate (ADAM) optimizer with an initial learning rate of .001. We measured error by taking the mean squared error of the output of our network with the label of the song pair [Figure 1]. We trained with a batch size of 16 over 5 epochs. 
